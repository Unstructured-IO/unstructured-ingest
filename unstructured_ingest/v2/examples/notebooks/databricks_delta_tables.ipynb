{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c570ed-8121-4f6f-89ed-2f18fb0abc5f",
   "metadata": {},
   "source": [
    "### Get credentials from environmet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c405b798-de48-4c13-8319-b0d2eb30c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydantic import BaseModel, SecretStr\n",
    "\n",
    "class EnvData(BaseModel):\n",
    "    server_hostname: str\n",
    "    http_path: str\n",
    "    access_token: SecretStr\n",
    "\n",
    "def get_env_data() -> EnvData:\n",
    "    return EnvData(\n",
    "        server_hostname=os.environ[\"DATABRICKS_SERVER_HOSTNAME\"],\n",
    "        http_path=os.environ[\"DATABRICKS_HTTP_PATH\"],\n",
    "        access_token=os.environ[\"DATABRICKS_ACCESS_TOKEN\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc9c436-4c08-4c33-96d8-df6538c3b7f0",
   "metadata": {},
   "source": [
    "### Set any reusable constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604d6e4d-6ce4-4b69-90a9-0922f2d2762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG = os.getenv(\"DATABRICKS_CATALOG\", \"utic-dev-tech-fixtures\")\n",
    "TABLE = os.getenv(\"DATABRICKS_TABLE\", \"elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e5898-c24c-4d8d-b29a-87610ec392b4",
   "metadata": {},
   "source": [
    "### Create reusable connection to databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f1ff81-0776-4927-b88d-f5241c498120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from databricks.sql.client import Connection as DeltaTableConnection\n",
    "from databricks.sql.client import Cursor as DeltaTableCursor\n",
    "from databricks.sql import connect\n",
    "\n",
    "@contextmanager\n",
    "def get_connection() -> DeltaTableConnection:\n",
    "    env_data = get_env_data()\n",
    "    with connect(\n",
    "        server_hostname=env_data.server_hostname,\n",
    "        http_path=env_data.http_path,\n",
    "        access_token=env_data.access_token.get_secret_value(),\n",
    "    ) as connection:\n",
    "        yield connection\n",
    "\n",
    "@contextmanager\n",
    "def get_cursor() -> DeltaTableCursor:\n",
    "    with get_connection() as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            yield cursor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb993608-19a7-4b84-a72f-4e5fc1fa1f70",
   "metadata": {},
   "source": [
    "### Reset database \n",
    "This makes sure we're using a fresh instance by dropping it if it already exists and recreating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ef991-f3a2-4888-b8e3-0486f580fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def get_schema_init_string() -> str:\n",
    "    schema_path = Path(\"test/integration/connectors/env_setup/sql/databricks_delta_tables/destination/schema.sql\")\n",
    "    with schema_path.open() as f:\n",
    "        data_lines = f.readlines()\n",
    "    data = \"\".join([line.strip() for line in data_lines])\n",
    "    return data\n",
    "\n",
    "def reset():\n",
    "    table_init_string = get_schema_init_string()\n",
    "    with get_cursor() as cursor:\n",
    "        cursor.execute(f\"USE CATALOG '{CATALOG}'\")\n",
    "        cursor.execute(f\"DROP TABLE IF EXISTS {TABLE}\")\n",
    "        cursor.execute(table_init_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7798dcf-ce32-4ff6-bf67-869089bf15cb",
   "metadata": {},
   "source": [
    "### Reading utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea91675-8f24-47a1-b7c9-6c071844dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count() -> int:\n",
    "    with get_cursor() as cursor:\n",
    "        cursor.execute(f\"USE CATALOG '{CATALOG}'\")\n",
    "        cursor.execute(f\"SELECT COUNT(*) FROM {TABLE}\")\n",
    "        count = cursor.fetchone()[0]\n",
    "        return count\n",
    "\n",
    "def get_content(limit : int = 10) -> list:\n",
    "    with get_cursor() as cursor:\n",
    "        cursor.execute(f\"USE CATALOG '{CATALOG}'\")\n",
    "        cursor.execute(f\"SELECT * FROM {TABLE} LIMIT {limit}\")\n",
    "        results = cursor.fetchall()\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0148da2-53c2-47a3-a6df-a7752a185e0f",
   "metadata": {},
   "source": [
    "### Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9e018-7f4f-42e7-9e3e-9f38c0c0dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure PYTHONPATH is set\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "base_path = Path(os.getcwd())\n",
    "project_dir = base_path.parents[3].as_posix()\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4818781f-97a5-40b4-b32a-ed6d524466ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from unstructured_ingest.v2.interfaces import ProcessorConfig\n",
    "from unstructured_ingest.v2.logger import logger\n",
    "from unstructured_ingest.v2.pipeline.pipeline import Pipeline\n",
    "from unstructured_ingest.v2.processes.chunker import ChunkerConfig\n",
    "from unstructured_ingest.v2.processes.connectors.local import (\n",
    "    LocalConnectionConfig,\n",
    "    LocalDownloaderConfig,\n",
    "    LocalIndexerConfig,\n",
    ")\n",
    "from unstructured_ingest.v2.processes.connectors.databricks.volumes_table import (\n",
    "    DatabricksVolumeDeltaTableStager,\n",
    "    DatabrickDeltaTablesUploadStagerConfig,\n",
    "    CONNECTOR_TYPE,\n",
    "    DatabricksVolumeDeltaTableUploaderConfig,\n",
    "    DatabricksVolumeDeltaTableUploader,\n",
    "    DatabrickDeltaTablesConnectionConfig,\n",
    ")\n",
    "from unstructured_ingest.v2.processes.connectors.sql.databricks_delta_tables import (\n",
    "    DatabrickDeltaTablesAccessConfig,\n",
    ")\n",
    "from unstructured_ingest.v2.processes.embedder import EmbedderConfig\n",
    "from unstructured_ingest.v2.processes.partitioner import PartitionerConfig\n",
    "\n",
    "base_path = Path(os.getcwd()).parents[3]\n",
    "docs_path = base_path / \"example-docs\"\n",
    "work_dir = base_path / \"tmp_ingest\" / CONNECTOR_TYPE\n",
    "output_path = work_dir / \"output\"\n",
    "download_path = work_dir / \"download\"\n",
    "\n",
    "env_data = get_env_data()\n",
    "\n",
    "Pipeline.from_configs(\n",
    "    context=ProcessorConfig(work_dir=str(work_dir.resolve())),\n",
    "    indexer_config=LocalIndexerConfig(\n",
    "        input_path=str(docs_path.resolve()) + \"/book-war-and-peace-1p.txt\"\n",
    "    ),\n",
    "    downloader_config=LocalDownloaderConfig(download_dir=download_path),\n",
    "    source_connection_config=LocalConnectionConfig(),\n",
    "    partitioner_config=PartitionerConfig(strategy=\"fast\"),\n",
    "    chunker_config=ChunkerConfig(chunking_strategy=\"by_title\"),\n",
    "    embedder_config=EmbedderConfig(embedding_provider=\"huggingface\"),\n",
    "    destination_connection_config=DatabrickDeltaTablesConnectionConfig(\n",
    "        access_config=DatabrickDeltaTablesAccessConfig(\n",
    "            token=env_data.access_token.get_secret_value()\n",
    "        ),\n",
    "        http_path=env_data.http_path,\n",
    "        server_hostname=env_data.server_hostname,\n",
    "    ),\n",
    "    stager_config=DatabrickDeltaTablesUploadStagerConfig(),\n",
    "    uploader_config=DatabricksVolumeDeltaTableUploaderConfig(\n",
    "        catalog=CATALOG,\n",
    "        database=\"default\",\n",
    "        table_name=TABLE,\n",
    "        volume=\"test-platform\",\n",
    "        volume_path=\"test-roman\",\n",
    "    ),\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c420b9e-8f30-44ce-bd98-cff0ab7d7771",
   "metadata": {},
   "source": [
    "### Validate upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ad7f74-3868-4f04-8f9a-709522f5b21f",
   "metadata": {},
   "source": [
    "**Count:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c1912c-5492-4a7a-99ea-bcb0daa8d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8705e99-9d13-48a9-87cf-a2af744c2b61",
   "metadata": {},
   "source": [
    "**Content:**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f2263e4-d747-47d8-b60b-cf42fb4d4319",
   "metadata": {},
   "source": [
    "get_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfc2353-f37a-47c7-a30a-81305a571cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
